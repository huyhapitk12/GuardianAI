# core/camera.py  # type: ignore
import cv2
import time
import threading
import queue
import gc
import platform
from typing import Optional, Callable, Tuple, Dict
from collections import deque
import numpy as np

from config import settings, AlertType

class Camera:
    """X·ª≠ l√Ω vi·ªác ch·ª•p v√† x·ª≠ l√Ω khung h√¨nh c·ªßa m√°y ·∫£nh"""
    
    def __init__(
        self,
        source,
        show_window: bool = False,
        on_person_alert: Optional[Callable] = None,
        on_fire_alert: Optional[Callable] = None,
        person_tracker=None
    ):
        self.source = source
        self.source_id = str(source)
        self.show_window = show_window
        self.on_person_alert = on_person_alert
        self.on_fire_alert = on_fire_alert
        self.person_tracker = person_tracker
        
        # Initialize capture with better error handling
        self.cap = None
        self._init_camera()
        
        # Tr·∫°ng th√°i
        self.quit = False
        self._frame_lock = threading.Lock()
        self._last_frame: Optional[np.ndarray] = None
        self._raw_frame: Optional[np.ndarray] = None
        self._prev_gray: Optional[np.ndarray] = None  # Khung h√¨nh grayscale tr∆∞·ªõc ƒë√≥ cho optical flow
        self._frame_idx = 0
        self._warmup_frames = 30  # B·ªè qua 30 khung h√¨nh ƒë·∫ßu ti√™n ƒë·ªÉ ·ªïn ƒë·ªãnh
        
        # C√†i ƒë·∫∑t k·∫øt n·ªëi l·∫°i (ƒë√£ c·∫£i thi·ªán)
        self._reconnect_attempts = 0
        self._max_reconnect_attempts = 10  # TƒÉng s·ªë l·∫ßn th·ª≠
        self._reconnect_delay = 5    # TƒÉng th·ªùi gian ch·ªù
        self._last_successful_frame = time.time()
        self._connection_timeout = 10  # gi√¢y kh√¥ng c√≥ khung h√¨nh th√†nh c√¥ng
        
        # H√†ng ƒë·ª£i x·ª≠ l√Ω
        self.fire_queue = queue.Queue(maxsize=2)
        self.behavior_queue = queue.Queue(maxsize=2)
        self.result_queue = queue.Queue(maxsize=16)
        
        # Tr·∫°ng th√°i ph√°t hi·ªán ch√°y
        self.recent_fire_detections = deque(
            maxlen=int(settings.camera.target_fps * settings.fire_logic.window_seconds) # L∆∞u tr·ªØ c√°c ph√°t hi·ªán trong X gi√¢y
        )
        self.current_fire_boxes = []
        self.red_alert_mode_active = False
        self.red_alert_mode_until = 0
        self.yellow_alert_mode_active = False
        self.yellow_alert_mode_until = 0

        self.fire_objects: Dict[int, Dict] = {}
        self.next_fire_object_id = 0
        self.alerted_fire_object_ids = set()
        
        print(f"INFO: Camera initialized: {self.source}")
        
        # L∆∞u tr·∫°ng th√°i b·∫≠t/t·∫Øt nh·∫≠n di·ªán ng∆∞·ªùi ·ªü khung g·∫ßn nh·∫•t ƒë·ªÉ ƒë·ªìng b·ªô v·∫Ω v·ªõi GUI
        self._last_person_detection_enabled = False
        
        # Tr·∫°ng th√°i ph√°t hi·ªán h·ªìng ngo·∫°i (IR)
        self._is_infrared_mode = False
        self._ir_detection_history = deque(maxlen=30)  # L·ªãch s·ª≠ 30 khung h√¨nh ƒë·ªÉ x√°c ƒë·ªãnh IR mode ·ªïn ƒë·ªãnh
        self._ir_mode_stable_frames = 0
        self._ir_mode_threshold = 0.7  # 70% khung h√¨nh ph·∫£i l√† IR ƒë·ªÉ x√°c nh·∫≠n ch·∫ø ƒë·ªô IR
        
        # Debug flag for fire detection
        self._debug_fire_detection = settings.camera.debug_fire_detection
        
        # Behavior analysis
        self.behavior_analyzer = None
        self._last_behavior_alert = 0
        self._behavior_alert_cooldown = settings.get('behavior.alert_cooldown', 30)
        
        # Stranger tracking for conditional behavior analysis
        self._has_stranger = False
        self._last_stranger_detection = 0
        self._stranger_timeout = 60  # seconds - how long to keep behavior analysis active after last stranger
        
        # IR Enhancement control
        self.ir_enhancement_enabled = settings.camera.infrared.enhancement.enabled

        # Visualization state
        self.current_pose = None
        self.current_anomaly_score = 0.0
    
    def _get_camera_backends(self):
        """Get camera backends based on platform"""
        if platform.system() == 'Windows':
            return [cv2.CAP_MSMF, cv2.CAP_DSHOW, cv2.CAP_ANY]
        elif platform.system() == 'Linux':
            return [cv2.CAP_V4L2, cv2.CAP_ANY]
        else:
            return [cv2.CAP_ANY]
    
    def _open_camera(self, source, backends):
        """Try to open camera with multiple backends"""
        if isinstance(source, int):
            for backend in backends:
                try:
                    self.cap = cv2.VideoCapture(source, backend)
                    if self.cap.isOpened():
                        print(f"INFO: Opened camera with backend {backend}")
                        return True
                except Exception:
                    continue
            return False
        else:
            self.cap = cv2.VideoCapture(source)
            return self.cap.isOpened()
    
    def _configure_camera(self):
        """Configure camera properties"""
        if not self.cap or not self.cap.isOpened():
            return False
        
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        try:
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 270)
            self.cap.set(cv2.CAP_PROP_FPS, 10)
        except Exception:
            pass
        
        return True
    
    def _enhance_ir_frame(self, frame: np.ndarray) -> np.ndarray:
        """Apply CLAHE to enhance IR frame contrast"""
        try:
            if not self.ir_enhancement_enabled:
                return frame
            
            # Convert to LAB to enhance L channel
            lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            clahe = cv2.createCLAHE(
                clipLimit=settings.camera.infrared.enhancement.clip_limit,
                tileGridSize=tuple(settings.camera.infrared.enhancement.tile_grid_size)
            )
            cl = clahe.apply(l)
            
            limg = cv2.merge((cl, a, b))
            enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
            return enhanced
        except Exception as e:
            print(f"ERROR: Enhancement error: {e}")
            return frame

    def _init_camera(self):
        """Initialize camera with fallback options"""
        try:
            backends = self._get_camera_backends()
            if not self._open_camera(self.source, backends):
                print(f"WARNING: Initial camera connection failed: {self.source}")
                if not self._reconnect():
                    print(f"ERROR: Could not open camera: {self.source}")
                    self.cap = None
                    return
            
            self._configure_camera()
        except Exception as e:
            print(f"ERROR: Failed to initialize camera {self.source}: {e}")
            self.cap = None
    
    def _detect_infrared_mode(self, frame: np.ndarray) -> bool:
        """Detect if camera is in infrared mode"""
        try:
            h, w = frame.shape[:2]
            sample_size = min(h, w, 100)
            step_h = max(1, h // sample_size)
            step_w = max(1, w // sample_size)
            sample = frame[::step_h, ::step_w]
            
            b, g, r = cv2.split(sample.astype(np.float32))
            
            channel_means = [float(np.mean(r.astype(np.float32))), float(np.mean(g.astype(np.float32))), float(np.mean(b.astype(np.float32)))]
            channel_std = np.std(np.array(channel_means))
            
            max_mean = max(channel_means)
            min_mean = min(channel_means)
            color_ratio = min_mean / max_mean if max_mean > 0 else 1.0
            
            hsv = cv2.cvtColor(sample.astype(np.uint8), cv2.COLOR_BGR2HSV)
            saturation_mean = float(np.mean(hsv[:, :, 1].astype(np.float32)))
            
            channel_std_threshold = settings.camera.infrared.detection.channel_std_threshold
            color_ratio_threshold = settings.camera.infrared.detection.color_ratio_threshold
            saturation_threshold = settings.camera.infrared.detection.saturation_threshold
            
            is_ir = (channel_std < channel_std_threshold) and (color_ratio > color_ratio_threshold) and (saturation_mean < saturation_threshold)
            
            self._ir_detection_history.append(is_ir)
            
            if len(self._ir_detection_history) >= 10:
                ir_count = sum(self._ir_detection_history)
                ir_ratio = ir_count / len(self._ir_detection_history)
                
                previous_mode = self._is_infrared_mode
                self._is_infrared_mode = ir_ratio >= self._ir_mode_threshold
                
                if previous_mode != self._is_infrared_mode:
                    mode_str = "INFRARED" if self._is_infrared_mode else "RGB"
                    print(f"Camera {self.source_id} switched to {mode_str} mode (ratio: {ir_ratio:.2%})")
            
            return self._is_infrared_mode
            
        except Exception as e:
            print(f"ERROR: Infrared detection error: {e}")
            return False
    
    def _reconnect(self) -> bool:
        """Attempt camera reconnection"""
        self._reconnect_attempts += 1
        
        if self._reconnect_attempts > self._max_reconnect_attempts:
            print(f"ERROR: Max reconnection attempts reached for camera {self.source_id}")
            return False
        
        print(f"INFO: Camera reconnect attempt ({self._reconnect_attempts}/{self._max_reconnect_attempts})")
        
        try:
            if self.cap:
                self.cap.release()
            
            time.sleep(self._reconnect_delay)
            
            backends = self._get_camera_backends()
            if not self._open_camera(self.source, backends):
                print(f"WARNING: Reconnection attempt {self._reconnect_attempts} failed")
                return False
            
            self._configure_camera()
            print("INFO: Camera reconnected successfully")
            self._reconnect_attempts = 0
            self._last_successful_frame = time.time()
            return True
                
        except Exception as e:
            print(f"ERROR: Reconnection error: {e}")
            return False
    
    def _check_connection_health(self) -> bool:
        """Check camera connection health"""
        current_time = time.time()
        time_since_last_frame = current_time - self._last_successful_frame
        
        if time_since_last_frame > self._connection_timeout:
            print(f"WARNING: Camera connection timeout ({time_since_last_frame:.1f}s)")
            return False
        
        return True
    
    def read(self) -> Tuple[bool, Optional[np.ndarray]]:
        """Read latest processed frame"""
        with self._frame_lock:
            if self._last_frame is not None:
                return True, self._last_frame.copy()
            return False, None
    
    def read_raw(self) -> Tuple[bool, Optional[np.ndarray]]:
        """Read latest raw frame"""
        with self._frame_lock:
            if self._raw_frame is not None:
                return True, self._raw_frame.copy()
            return False, None
    
    def start_workers(self, fire_detector, face_detector, behavior_analyzer=None):
        """Start background worker threads"""
        self.fire_detector = fire_detector
        self.face_detector = face_detector
        self.behavior_analyzer = behavior_analyzer
        
        threading.Thread(
            target=self._fire_worker,
            daemon=True
        ).start()
        print("INFO: Fire detection worker started")
        
        if self.behavior_analyzer:
            threading.Thread(
                target=self._behavior_worker,
                daemon=True
            ).start()
            print("INFO: Behavior analysis worker started")
    
    def _fire_worker(self):
        """Background worker for fire detection"""
        while not self.quit:
            try:
                frame = self.fire_queue.get(timeout=1.0)
            except queue.Empty:
                continue
            
            if self.fire_detector is None:
                continue
            
            try:
                detections = self.fire_detector.detect(frame)
                if detections:
                    self.result_queue.put(("fire", detections))
            except Exception as e:
                print(f"ERROR: Fire worker error: {e}")
    def _behavior_worker(self):
        """Background worker for behavior analysis"""
        skip_counter = 0
        process_every_n = settings.get('behavior.process_every_n_frames', 3)
        
        while not self.quit:
            try:
                frame = self.behavior_queue.get(timeout=1.0)
                
                # Skip frames for performance
                skip_counter += 1
                if skip_counter % process_every_n != 0:
                    continue
                
                # New AnomalyDetector returns (frame, score, is_anomaly, pose)
                annotated_frame, score, is_anomaly, pose = self.behavior_analyzer.process_frame(frame)
                
                # Update state for visualization
                self.current_pose = pose
                self.current_anomaly_score = score
                
                # Update person tracker with behavior info
                if self.person_tracker and pose and pose.bbox:
                    try:
                        # Calculate scale factors
                        # We need original frame size. Assuming self.cap is available and valid.
                        # If not, we can't scale accurately, but usually it is.
                        # Or we can use self._raw_frame size if available.
                        orig_w = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH) if self.cap else 0
                        orig_h = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT) if self.cap else 0
                        
                        if orig_w > 0 and orig_h > 0:
                            proc_w, proc_h = settings.camera.process_size
                            scale_x = orig_w / proc_w
                            scale_y = orig_h / proc_h
                            
                            self.person_tracker.update_behavior_status(
                                pose.bbox, 
                                score, 
                                is_anomaly, 
                                scale_x, 
                                scale_y
                            )
                    except Exception as e:
                        print(f"ERROR: Failed to update behavior status: {e}")
                
                if is_anomaly:
                    # Check cooldown
                    now = time.time()
                    if now - self._last_behavior_alert >= self._behavior_alert_cooldown:
                        # Create a simple result object/dict
                        result = {
                            'score': score,
                            'timestamp': now,
                            'is_anomaly': is_anomaly
                        }
                        self.result_queue.put(('behavior', result, annotated_frame))
                        self._last_behavior_alert = now
                        
            except queue.Empty:
                continue
            except Exception as e:
                print(f"ERROR: Behavior worker error: {e}")

    def process_frames(self, state_manager):
        """Main frame processing loop"""
        frame_interval = 1.0 / settings.camera.target_fps
        last_time = 0
        frame_buffer = None
        
        while not self.quit:
            now = time.time()
            
            if now - last_time < frame_interval:
                time.sleep(0.001)
                continue
            last_time = now
            
            if not self.cap or not self.cap.isOpened():
                if not self._reconnect():
                    time.sleep(2.0)
                    continue
            
            try:
                ret, frame = self.cap.read()
                if not ret or frame is None:
                    if not self._check_connection_health():
                        if not self._reconnect():
                            time.sleep(1.0)
                            continue
                    else:
                        time.sleep(0.005)
                        continue
                        
            except cv2.error as cv_err:
                print(f"ERROR: OpenCV error: {cv_err}")
                time.sleep(0.5)
                continue
            except Exception as e:
                print(f"ERROR: Frame read error: {e}")
                time.sleep(0.5)
                continue
            
            self._last_successful_frame = time.time()
            self._frame_idx += 1
            orig_h, orig_w = frame.shape[:2]
            
            if self._frame_idx % 10 == 0:
                self._detect_infrared_mode(frame)
            
            # Apply IR enhancement if needed
            if self._is_infrared_mode:
                frame = self._enhance_ir_frame(frame)
            
            person_detection_enabled = state_manager.is_person_detection_enabled(self.source_id)
            self._last_person_detection_enabled = person_detection_enabled
            
            try:
                if frame_buffer is None or frame_buffer.shape[:2] != tuple(settings.camera.process_size):
                    small_frame = cv2.resize(frame, tuple(settings.camera.process_size), interpolation=cv2.INTER_LINEAR)
                    frame_buffer = small_frame.copy()
                else:
                    cv2.resize(frame, tuple(settings.camera.process_size), dst=frame_buffer, interpolation=cv2.INTER_LINEAR)
                    small_frame = frame_buffer
            except Exception as e:
                print(f"ERROR: Resize error: {e}")
            
            # Calculate scale factors for mapping detections back to original frame
            scale_x = orig_w / settings.camera.process_size[0]
            scale_y = orig_h / settings.camera.process_size[1]
            
            # Person Detection
            if person_detection_enabled:
                self._process_persons(small_frame, frame, scale_x, scale_y, now)

            # Fire Detection
            if self.fire_detector and not self.fire_queue.full():
                self.fire_queue.put(small_frame.copy())
                
            # Behavior Analysis
            if self.behavior_analyzer and not self.behavior_queue.full():
                self.behavior_queue.put(small_frame.copy())
            
            self.current_fire_boxes = []
            self._process_fire_results(scale_x, scale_y, now, frame)
            
            if self.show_window or person_detection_enabled:
                display_frame = frame.copy()
                self._draw_visualizations(display_frame, person_detection_enabled)
                
                # C·∫≠p nh·∫≠t c√°c khung h√¨nh ƒë√£ l∆∞u
                self._update_frames(display_frame, frame)
                
                # Hi·ªÉn th·ªã c·ª≠a s·ªï n·∫øu ƒë∆∞·ª£c b·∫≠t
                if self.show_window:
                    try:
                        cv2.imshow("Guardian Detection", display_frame)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            self.quit = True
                    except Exception as show_err:
                        print(f"WARNING: Failed to show window: {show_err}")
            else:
                # Khi nh·∫≠n di·ªán t·∫Øt, v·∫´n c·∫≠p nh·∫≠t c·∫£ hai khung h√¨nh ƒë·ªÉ GUI ho·∫°t ƒë·ªông
                self._update_frames(frame, frame)
        
        self.release()

    def _process_persons(
        self,
        small_frame: np.ndarray,
        full_frame: np.ndarray,
        scale_x: float,
        scale_y: float,
        now: float
    ):
        """X·ª≠ l√Ω ph√°t hi·ªán v√† theo d√µi ng∆∞·ªùi"""
        try:
            if not self.person_tracker:
                return
            
            # Determine threshold
            threshold = settings.detection.person_confidence_threshold
            if self._is_infrared_mode:
                threshold = settings.camera.infrared.person_detection_threshold
                
            detections = self.person_tracker.detect_persons(small_frame, conf_threshold=threshold)
            self.person_tracker.update_tracks(
                detections,
                full_frame,
                scale_x,
                scale_y
            )
            
            # Ki·ªÉm tra c·∫£nh b√°o
            alerts = self.person_tracker.check_confirmations()
            for track_id, alert_type, metadata in alerts:
                # Track stranger detection for conditional behavior analysis
                if alert_type == "nguoi_la":  # AlertType.STRANGER.value
                    self._has_stranger = True
                    self._last_stranger_detection = now
                    print(f"INFO: Stranger detected - activating behavior analysis for {self._stranger_timeout}s")
                
                if self.on_person_alert:
                    # T·∫°o frame ch√∫ th√≠ch gi·ªëng GUI ƒë·ªÉ g·ª≠i Telegram
                    alert_frame = full_frame.copy()
                    self._draw_visualizations(alert_frame, True)
                    self.on_person_alert(self.source_id, alert_frame, alert_type, metadata)
        except Exception as e:
            print(f"ERROR: Person processing error: {e}")

    def _process_fire_results(
        self,
        scale_x: float,
        scale_y: float,
        now: float,
        frame: np.ndarray
    ):
        """X·ª≠ l√Ω k·∫øt qu·∫£ ph√°t hi·ªán ch√°y v√† h√†nh vi t·ª´ h√†ng ƒë·ª£i"""
        try:
            while not self.result_queue.empty():
                result_tuple = self.result_queue.get_nowait()
                result_type = result_tuple[0]
                
                if result_type == "fire":
                    results = result_tuple[1]
                    self._handle_fire_detections(
                        results,
                        scale_x,
                        scale_y,
                        now,
                        frame
                    )
                elif result_type == "behavior":
                    behavior_result = result_tuple[1]
                    alert_frame = result_tuple[2]
                    self._handle_behavior_detection(behavior_result, alert_frame)
        except queue.Empty:
            pass
    
    def _handle_behavior_detection(self, result, frame):
        """Handle behavior anomaly detection"""
        if self.on_person_alert:
            # Handle both object and dict for backward compatibility/flexibility
            score = result.get('score') if isinstance(result, dict) else result.score
            timestamp = result.get('timestamp') if isinstance(result, dict) else result.timestamp
            
            metadata = {
                'score': score,
                'timestamp': timestamp
            }
            self.on_person_alert(
                self.source_id,
                frame,
                AlertType.ANOMALOUS_BEHAVIOR.value,
                metadata
            )

    def _check_motion_infrared(self, frame: np.ndarray, bbox: Tuple[int, int, int, int], motion_threshold: float, motion_std_min: float, debug: bool = False) -> bool:
        """
        Ki·ªÉm tra chuy·ªÉn ƒë·ªông trong v√πng ƒë·ªÉ x√°c ƒë·ªãnh l·ª≠a th·ª±c
        Phi√™n b·∫£n ƒë∆°n gi·∫£n cho IR mode
        
        Args:
            frame: Khung h√¨nh ƒë·∫ßy ƒë·ªß
            bbox: Bounding box c·∫ßn ki·ªÉm tra
            motion_threshold: Ng∆∞·ª°ng magnitude chuy·ªÉn ƒë·ªông
            motion_std_min: ƒê·ªô l·ªách chu·∫©n magnitude t·ªëi thi·ªÉu
            debug: B·∫≠t/t·∫Øt debug log
        """
        try:
            x1, y1, x2, y2 = bbox
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            
            # M·ªü r·ªông v√πng ki·ªÉm tra m·ªôt ch√∫t
            margin = 5
            x1_ext = max(0, x1 - margin)
            y1_ext = max(0, y1 - margin)
            x2_ext = min(frame.shape[1], x2 + margin)
            y2_ext = min(frame.shape[0], y2 + margin)
            
            roi = frame[y1_ext:y2_ext, x1_ext:x2_ext]
            if roi.size == 0 or roi.shape[0] < 5 or roi.shape[1] < 5:
                return True  # V√πng qu√° nh·ªè, b·ªè qua ki·ªÉm tra motion
            
            # Chuy·ªÉn sang grayscale
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            
            # Ki·ªÉm tra khung h√¨nh tr∆∞·ªõc
            if self._prev_gray is None or self._prev_gray.shape != gray.shape:
                self._prev_gray = gray.copy()
                return True  # Ch∆∞a c√≥ khung h√¨nh tr∆∞·ªõc, ch·∫•p nh·∫≠n
            
            # T√≠nh optical flow
            flow = cv2.calcOpticalFlowFarneback(
                self._prev_gray, gray,
                np.zeros_like(self._prev_gray),
                0.5, 3, 15, 3, 5, 1.2, 0
            )
            
            # C·∫≠p nh·∫≠t khung h√¨nh tr∆∞·ªõc
            self._prev_gray = gray.copy()
            
            # T√≠nh ƒë·ªô l·ªõn c·ªßa vector chuy·ªÉn ƒë·ªông
            magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)
            
            # T√≠nh c√°c ch·ªâ s·ªë chuy·ªÉn ƒë·ªông
            magnitude_mean = float(np.mean(magnitude))
            magnitude_std = float(np.std(magnitude))
            strong_motion_pixels = np.sum(magnitude > motion_threshold)
            motion_ratio = strong_motion_pixels / magnitude.size if magnitude.size > 0 else 0
            
            # L·ª≠a c√≥ chuy·ªÉn ƒë·ªông: magnitude_std > ng∆∞·ª°ng
            # Trong ch·∫ø ƒë·ªô IR, gi·∫£m ng∆∞·ª°ng m·ªôt ch√∫t ƒë·ªÉ nh·∫°y h∆°n
            std_threshold = motion_std_min * 0.8 if self._is_infrared_mode else motion_std_min
            has_motion = magnitude_std > std_threshold
            
            if debug and self._debug_fire_detection:
                print(f"‚îÅ‚îÅ‚îÅ MOTION CHECK ‚îÅ‚îÅ‚îÅ")
                print(f"  üìä Magnitude: mean={magnitude_mean:.3f}, std={magnitude_std:.3f}")
                print(f"  üéØ Threshold: motion_std_min={motion_std_min:.3f} (adj: {std_threshold:.3f})")
                print(f"  üìà Strong motion pixels: {strong_motion_pixels} ({motion_ratio:.1%})")
                if has_motion:
                    print(f"  ‚úÖ Motion detected: std={magnitude_std:.3f} > {std_threshold:.3f}")
                else:
                    print(f"  ‚ùå Static/slow motion: std={magnitude_std:.3f} <= {std_threshold:.3f}")
            
            return has_motion
            
        except Exception as e:
            if debug and self._debug_fire_detection:
                print(f"‚ö†Ô∏è  Motion check error: {e}")
            # Khi c√≥ l·ªói, ch·∫•p nh·∫≠n (kh√¥ng reject)
            return True

    def _is_valid_yellow_alert_infrared(self, frame: np.ndarray, bbox: Tuple[int, int, int, int], debug: bool = False) -> bool:
            """
            B·ªô l·ªçc cho c·∫£nh b√°o v√†ng trong ch·∫ø ƒë·ªô h·ªìng ngo·∫°i
            
            C·∫£nh b√°o v√†ng ·ªü ch·∫ø ƒë·ªô IR c·∫ßn:
            - Ti√™u ch√≠ l·ªèng h∆°n c·∫£nh b√°o ƒë·ªè
            - V·∫´n lo·∫°i b·ªè c√°c false positive r√µ r√†ng
            - Cho ph√©p c√°c ph√°t hi·ªán nghi ng·ªù ƒë·ªÉ ng∆∞·ªùi d√πng xem x√©t
            """
            try:
                x1, y1, x2, y2 = bbox
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                
                # B·ªè qua bbox qu√° nh·ªè (l·ªèng h∆°n red alert)
                roi_width = x2 - x1
                roi_height = y2 - y1
                if roi_width < 3 or roi_height < 3:
                    if debug:
                        print(f"‚ùå YELLOW IR FAIL: ROI qu√° nh·ªè ({roi_width}x{roi_height})")
                    return False
                
                # Clamp bbox
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(frame.shape[1], x2)
                y2 = min(frame.shape[0], y2)
                
                roi = frame[y1:y2, x1:x2]
                if roi.size == 0:
                    return False
                
                # Chuy·ªÉn sang grayscale
                gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY).astype(np.float32)
                
                # ===== TI√äU CH√ç 1: ƒê·ªô s√°ng (l·ªèng h∆°n) =====
                brightness_mean = np.mean(gray_roi)
                brightness_max = np.max(gray_roi)
                
                # L·∫•y ng∆∞·ª°ng t·ª´ config
                brightness_mean_min = settings.camera.infrared.yellow_alert.brightness_mean_min
                brightness_max_min = settings.camera.infrared.yellow_alert.brightness_max_min
                
                if brightness_mean < brightness_mean_min and brightness_max < brightness_max_min:
                    if debug:
                        print(f"‚ùå YELLOW IR FAIL T1: ƒê·ªô s√°ng th·∫•p")
                        print(f"   ƒêo ƒë∆∞·ª£c: mean={brightness_mean:.1f}, max={brightness_max:.1f}")
                        print(f"   Y√™u c·∫ßu: mean>={brightness_mean_min} OR max>={brightness_max_min}")
                    return False
                
                if debug:
                    print(f"‚úÖ YELLOW IR PASS T1: ƒê·ªô s√°ng OK")
                    print(f"   ƒêo ƒë∆∞·ª£c: mean={brightness_mean:.1f}, max={brightness_max:.1f}")
                    print(f"   Y√™u c·∫ßu: mean>={brightness_mean_min} OR max>={brightness_max_min}")
                
                # ===== TI√äU CH√ç 2: Bi·∫øn ƒë·ªïi c∆∞·ªùng ƒë·ªô (l·ªèng h∆°n) =====
                brightness_std = np.std(gray_roi)
                
                # L·∫•y ng∆∞·ª°ng t·ª´ config
                brightness_std_min = settings.camera.infrared.yellow_alert.brightness_std_min
                
                if brightness_std < brightness_std_min:
                    if debug:
                        print(f"‚ùå YELLOW IR FAIL T2: Qu√° ƒë·ªìng nh·∫•t")
                        print(f"   ƒêo ƒë∆∞·ª£c: std={brightness_std:.1f}")
                        print(f"   Y√™u c·∫ßu: std>={brightness_std_min}")
                    return False
                
                if debug:
                    print(f"‚úÖ YELLOW IR PASS T2: Bi·∫øn ƒë·ªïi OK")
                    print(f"   ƒêo ƒë∆∞·ª£c: std={brightness_std:.1f}")
                    print(f"   Y√™u c·∫ßu: std>={brightness_std_min}")
                
                # ===== TI√äU CH√ç 3: Lo·∫°i b·ªè v√πng qu√° s√°ng (glare) =====
                # L·∫•y ng∆∞·ª°ng t·ª´ config
                very_bright_threshold = settings.camera.infrared.yellow_alert.very_bright_threshold
                very_bright_ratio_max = settings.camera.infrared.yellow_alert.very_bright_ratio_max
                
                very_bright_pixels = np.sum(gray_roi > very_bright_threshold)
                very_bright_ratio = very_bright_pixels / gray_roi.size if gray_roi.size > 0 else 0
                
                if very_bright_ratio > very_bright_ratio_max:
                    if debug:
                        print(f"‚ùå YELLOW IR FAIL T3: Ph·∫£n x·∫°/glare (qu√° s√°ng ƒë·ªìng nh·∫•t)")
                        print(f"   ƒêo ƒë∆∞·ª£c: {very_bright_pixels} pixels ({very_bright_ratio:.2%})")
                        print(f"   Y√™u c·∫ßu: >{very_bright_threshold} brightness, <={very_bright_ratio_max:.2%} ratio")
                    return False
                
                if debug:
                    print(f"‚úÖ YELLOW IR PASS T3: Kh√¥ng ph·∫£i glare")
                    print(f"   ƒêo ƒë∆∞·ª£c: {very_bright_pixels} pixels ({very_bright_ratio:.2%})")
                    print(f"   Y√™u c·∫ßu: >{very_bright_threshold} brightness, <={very_bright_ratio_max:.2%} ratio")
                
                # ===== TI√äU CH√ç 4: Lo·∫°i b·ªè v√πng qu√° t·ªëi ƒë·ªìng nh·∫•t =====
                # L·∫•y ng∆∞·ª°ng t·ª´ config
                very_dark_threshold = settings.camera.infrared.yellow_alert.very_dark_threshold
                very_dark_ratio_max = settings.camera.infrared.yellow_alert.very_dark_ratio_max
                
                very_dark_pixels = np.sum(gray_roi < very_dark_threshold)
                very_dark_ratio = very_dark_pixels / gray_roi.size if gray_roi.size > 0 else 0
                
                if very_dark_ratio > very_dark_ratio_max:
                    if debug:
                        print(f"‚ùå YELLOW IR FAIL T4: V√πng qu√° t·ªëi")
                        print(f"   ƒêo ƒë∆∞·ª£c: {very_dark_pixels} pixels ({very_dark_ratio:.2%})")
                        print(f"   Y√™u c·∫ßu: <{very_dark_threshold} brightness, <={very_dark_ratio_max:.2%} ratio")
                    return False
                
                if debug:
                    print(f"‚úÖ YELLOW IR PASS T4: Kh√¥ng qu√° t·ªëi")
                    print(f"   ƒêo ƒë∆∞·ª£c: {very_dark_pixels} pixels ({very_dark_ratio:.2%})")
                    print(f"   Y√™u c·∫ßu: <{very_dark_threshold} brightness, <={very_dark_ratio_max:.2%} ratio")
                
                # ===== TI√äU CH√ç 5: Ki·ªÉm tra chuy·ªÉn ƒë·ªông (n·∫øu ƒë∆∞·ª£c b·∫≠t) =====
                if settings.camera.infrared.yellow_alert.check_motion:
                    motion_threshold = settings.camera.infrared.yellow_alert.motion_threshold
                    motion_std_min = settings.camera.infrared.yellow_alert.motion_std_min
                    
                    has_motion = self._check_motion_infrared(frame, bbox, motion_threshold, motion_std_min, debug)
                    if not has_motion:
                        if debug:
                            print(f"‚ùå YELLOW IR FAIL T5: Kh√¥ng c√≥ chuy·ªÉn ƒë·ªông ƒë·∫∑c tr∆∞ng c·ªßa l·ª≠a")
                        return False
                    
                    if debug:
                        print(f"‚úÖ YELLOW IR PASS T5: C√≥ chuy·ªÉn ƒë·ªông")
                
                # ‚úÖ PASS T·∫§T C·∫¢ C√ÅC TI√äU CH√ç
                if debug:
                    print(f"üü° ‚úÖ YELLOW ALERT VALIDATED (IR MODE): bright={brightness_mean:.0f}, std={brightness_std:.0f}\n")
                
                return True
                
            except Exception as e:
                if debug:
                    print(f"‚ö†Ô∏è  Yellow IR filter error: {e}")
                # Khi c√≥ l·ªói, ch·∫•p nh·∫≠n detection t·ª´ YOLO
                return True
    
    def _is_valid_fire_infrared(self, frame: np.ndarray, bbox: Tuple[int, int, int, int], debug: bool = False) -> bool:
        """
        B·ªô l·ªçc cho ch·∫ø ƒë·ªô h·ªìng ngo·∫°i
        
        ·ªû ch·∫ø ƒë·ªô IR, kh√¥ng th·ªÉ d·ª±a v√†o m√†u s·∫Øc, ch·ªâ c√≥ th·ªÉ d√πng:
        - ƒê·ªô s√°ng cao (nhi·ªát ph√°t ra √°nh s√°ng h·ªìng ngo·∫°i)
        - Bi·∫øn ƒë·ªïi c∆∞·ªùng ƒë·ªô (l·ª≠a nh·∫•p nh√°y)
        - V√πng s√°ng t·∫≠p trung (kh√¥ng ph·∫£i √°nh s√°ng m√¥i tr∆∞·ªùng)
        """
        try:
            x1, y1, x2, y2 = bbox
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            
            # B·ªè qua bbox qu√° nh·ªè
            roi_width = x2 - x1
            roi_height = y2 - y1
            if roi_width < 5 or roi_height < 5:
                if debug:
                    print(f"‚ùå IR FAIL: ROI qu√° nh·ªè ({roi_width}x{roi_height})")
                return False
            
            # Clamp bbox
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(frame.shape[1], x2)
            y2 = min(frame.shape[0], y2)
            
            roi = frame[y1:y2, x1:x2]
            if roi.size == 0:
                return False
            
            # Chuy·ªÉn sang grayscale ƒë·ªÉ ph√¢n t√≠ch ƒë·ªô s√°ng
            gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY).astype(np.float32)
            
            # ===== TI√äU CH√ç 1: ƒê·ªô s√°ng cao =====
            # L·ª≠a trong IR th∆∞·ªùng r·∫•t s√°ng do ph√°t nhi·ªát
            brightness_mean = np.mean(gray_roi)
            brightness_max = np.max(gray_roi)
            
            # L·∫•y ng∆∞·ª°ng t·ª´ config
            brightness_mean_min = settings.camera.infrared.red_alert.brightness_mean_min
            brightness_max_min = settings.camera.infrared.red_alert.brightness_max_min
            
            if brightness_mean < brightness_mean_min and brightness_max < brightness_max_min:
                if debug:
                    print(f"‚ùå IR FAIL T1: ƒê·ªô s√°ng th·∫•p")
                    print(f"   ƒêo ƒë∆∞·ª£c: mean={brightness_mean:.1f}, max={brightness_max:.1f}")
                    print(f"   Y√™u c·∫ßu: mean>={brightness_mean_min} OR max>={brightness_max_min}")
                return False
            
            if debug:
                print(f"‚úÖ IR PASS T1: ƒê·ªô s√°ng OK")
                print(f"   ƒêo ƒë∆∞·ª£c: mean={brightness_mean:.1f}, max={brightness_max:.1f}")
                print(f"   Y√™u c·∫ßu: mean>={brightness_mean_min} OR max>={brightness_max_min}")
            
            # ===== TI√äU CH√ç 2: Bi·∫øn ƒë·ªïi c∆∞·ªùng ƒë·ªô =====
            # L·ª≠a c√≥ bi·∫øn ƒë·ªïi ƒë·ªô s√°ng, kh√¥ng ƒë·ªìng nh·∫•t
            brightness_std = np.std(gray_roi)
            
            # L·∫•y ng∆∞·ª°ng t·ª´ config
            brightness_std_min = settings.camera.infrared.red_alert.brightness_std_min
            
            # V·ªõi ·∫£nh ƒë√£ enhance, ƒë·ªô t∆∞∆°ng ph·∫£n tƒÉng n√™n std c≈©ng tƒÉng, nh∆∞ng ta v·∫´n gi·∫£m ng∆∞·ª°ng check
            # ƒë·ªÉ ƒë·∫£m b·∫£o b·∫Øt ƒë∆∞·ª£c l·ª≠a nh·ªè
            if brightness_std < (brightness_std_min * 0.8):
                if debug:
                    print(f"‚ùå IR FAIL T2: Qu√° ƒë·ªìng nh·∫•t")
                    print(f"   ƒêo ƒë∆∞·ª£c: std={brightness_std:.1f}")
                    print(f"   Y√™u c·∫ßu: std>={brightness_std_min}")
                return False
            
            if debug:
                print(f"‚úÖ IR PASS T2: Bi·∫øn ƒë·ªïi OK")
                print(f"   ƒêo ƒë∆∞·ª£c: std={brightness_std:.1f}")
                print(f"   Y√™u c·∫ßu: std>={brightness_std_min}")
            
            # ===== TI√äU CH√ç 3: V√πng s√°ng t·∫≠p trung =====
            # L·ª≠a c√≥ v√πng s√°ng t·∫≠p trung, kh√¥ng ph·∫£i √°nh s√°ng m√¥i tr∆∞·ªùng r·∫£i r√°c
            # L·∫•y ng∆∞·ª°ng t·ª´ config
            bright_pixel_threshold = settings.camera.infrared.red_alert.bright_pixel_threshold
            bright_pixel_ratio_min = settings.camera.infrared.red_alert.bright_pixel_ratio_min
            
            bright_pixels = np.sum(gray_roi > bright_pixel_threshold)
            bright_ratio = bright_pixels / gray_roi.size if gray_roi.size > 0 else 0
            
            if bright_ratio < bright_pixel_ratio_min:
                if debug:
                    print(f"‚ùå IR FAIL T3: Kh√¥ng ƒë·ªß v√πng s√°ng t·∫≠p trung")
                    print(f"   ƒêo ƒë∆∞·ª£c: {bright_pixels} pixels ({bright_ratio:.2%})")
                    print(f"   Y√™u c·∫ßu: >{bright_pixel_threshold} brightness, >={bright_pixel_ratio_min:.2%} ratio")
                return False
            
            if debug:
                print(f"‚úÖ IR PASS T3: V√πng s√°ng OK")
                print(f"   ƒêo ƒë∆∞·ª£c: {bright_pixels} pixels ({bright_ratio:.2%})")
                print(f"   Y√™u c·∫ßu: >{bright_pixel_threshold} brightness, >={bright_pixel_ratio_min:.2%} ratio")
            
            # ===== TI√äU CH√ç 4: Lo·∫°i b·ªè v√πng qu√° s√°ng ƒë·ªìng nh·∫•t (√°nh s√°ng ph·∫£n x·∫°) =====
            # L·∫•y ng∆∞·ª°ng t·ª´ config
            very_bright_threshold = settings.camera.infrared.red_alert.very_bright_threshold
            very_bright_ratio_max = settings.camera.infrared.red_alert.very_bright_ratio_max
            
            very_bright_pixels = np.sum(gray_roi > very_bright_threshold)
            very_bright_ratio = very_bright_pixels / gray_roi.size if gray_roi.size > 0 else 0
            
            if very_bright_ratio > very_bright_ratio_max:
                if debug:
                    print(f"‚ùå IR FAIL T4: Ph·∫£n x·∫°/glare (qu√° s√°ng ƒë·ªìng nh·∫•t)")
                    print(f"   ƒêo ƒë∆∞·ª£c: {very_bright_pixels} pixels ({very_bright_ratio:.2%})")
                    print(f"   Y√™u c·∫ßu: >{very_bright_threshold} brightness, <={very_bright_ratio_max:.2%} ratio")
                return False
            
            if debug:
                print(f"‚úÖ IR PASS T4: Kh√¥ng ph·∫£i glare")
                print(f"   ƒêo ƒë∆∞·ª£c: {very_bright_pixels} pixels ({very_bright_ratio:.2%})")
                print(f"   Y√™u c·∫ßu: >{very_bright_threshold} brightness, <={very_bright_ratio_max:.2%} ratio")
            
            # ===== TI√äU CH√ç 5: Ki·ªÉm tra chuy·ªÉn ƒë·ªông (n·∫øu ƒë∆∞·ª£c b·∫≠t) =====
            if settings.camera.infrared.red_alert.check_motion:
                motion_threshold = settings.camera.infrared.red_alert.motion_threshold
                motion_std_min = settings.camera.infrared.red_alert.motion_std_min
                
                has_motion = self._check_motion_infrared(frame, bbox, motion_threshold, motion_std_min, debug)
                if not has_motion:
                    if debug:
                        print(f"‚ùå IR FAIL T5: Kh√¥ng c√≥ chuy·ªÉn ƒë·ªông ƒë·∫∑c tr∆∞ng c·ªßa l·ª≠a")
                    return False
                
                if debug:
                    print(f"‚úÖ IR PASS T5: C√≥ chuy·ªÉn ƒë·ªông")
            
            # ‚úÖ PASS T·∫§T C·∫¢ C√ÅC TI√äU CH√ç
            if debug:
                print(f"üî• ‚úÖ FIRE VALIDATED (IR MODE): bright={brightness_mean:.0f}, std={brightness_std:.0f}, bright_ratio={bright_ratio:.2%}\n")
            
            return True
            
        except Exception as e:
            if debug:
                print(f"‚ö†Ô∏è  IR filter error: {e}")
            # Khi c√≥ l·ªói, ch·∫•p nh·∫≠n detection t·ª´ YOLO
            return True
    
    def _is_valid_fire_color(self, frame: np.ndarray, bbox: Tuple[int, int, int, int], debug: bool = False) -> bool:
        """
        B·ªô l·ªçc ph√¢n bi·ªát l·ª≠a th·ª±c vs √°nh s√°ng ch√≥i/glare
        
        Chi·∫øn l∆∞·ª£c:
        - L·ª≠a th·ª±c: M√†u ƒë·ªè/cam/v√†ng + ƒë·ªô s√°ng cao + c√≥ bi·∫øn ƒë·ªïi c∆∞·ªùng ƒë·ªô
        - √Ånh s√°ng ch√≥i: Tr·∫Øng s√°ng + saturation th·∫•p + R‚âàG‚âàB
        - Kh√≥i: C√≥ th·ªÉ x√°m nh·∫°t, c·∫ßn relax h∆°n
        - Ch·∫ø ƒë·ªô h·ªìng ngo·∫°i: B·ªè qua ki·ªÉm tra m√†u s·∫Øc, ch·ªâ d·ª±a v√†o ƒë·ªô s√°ng v√† bi·∫øn ƒë·ªïi
        
        ƒê∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ c√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† recall
        """
        try:
            # N·∫øu ·ªü ch·∫ø ƒë·ªô h·ªìng ngo·∫°i, √°p d·ª•ng logic ƒë∆°n gi·∫£n h∆°n
            if self._is_infrared_mode:
                return self._is_valid_fire_infrared(frame, bbox, debug)
            
            x1, y1, x2, y2 = bbox
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            
            # B·ªè qua bbox qu√° nh·ªè
            roi_width = x2 - x1
            roi_height = y2 - y1
            if roi_width < 5 or roi_height < 5:  # Gi·∫£m t·ª´ 10 -> 5
                return False
            
            # Clamp bbox v√†o frame
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(frame.shape[1], x2)
            y2 = min(frame.shape[0], y2)
            
            roi = frame[y1:y2, x1:x2]
            if roi.size == 0:
                return False

            # Chuy·ªÉn sang HSV ƒë·ªÉ ph√¢n t√≠ch m√†u s·∫Øc
            hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV).astype(np.float32)
            h, s, v = cv2.split(hsv_roi)
            
            # ===== TI√äU CH√ç 1: Hue (m√†u s·∫Øc) - RELAXED =====
            # Ch·∫•p nh·∫≠n d·∫£i m√†u r·ªông h∆°n: ƒë·ªè, cam, v√†ng
            red_mask = ((h >= 0) & (h <= 15)) | ((h >= 165) & (h <= 180))  # M·ªü r·ªông t·ª´ 10/170 -> 15/165
            orange_yellow_mask = (h >= 5) & (h <= 50)  # M·ªü r·ªông t·ª´ 48 -> 50
            hue_mask = red_mask | orange_yellow_mask
            
            hue_pixels = np.sum(hue_mask)
            hue_ratio = hue_pixels / hue_mask.size if hue_mask.size > 0 else 0
            
            # Gi·∫£m threshold t·ª´ 0.1993 -> 0.10 (10% thay v√¨ 20%)
            if hue_ratio < 0.10:
                if debug:
                    print(f"‚ùå FAIL T1: Kh√¥ng ƒë·ªß m√†u l·ª≠a")
                    print(f"   ƒêo ƒë∆∞·ª£c: {hue_pixels} pixels ({hue_ratio:.2%})")
                    print(f"   Y√™u c·∫ßu: Hue 0-15¬∞ ho·∫∑c 165-180¬∞ (ƒë·ªè) ho·∫∑c 5-50¬∞ (cam-v√†ng), >=10% pixels")
                return False
            
            if debug:
                print(f"‚úÖ PASS T1: Hue OK")
                print(f"   ƒêo ƒë∆∞·ª£c: {hue_pixels} pixels ({hue_ratio:.2%}), y√™u c·∫ßu >=10%")
            
            # ===== TI√äU CH√ç 2: Brightness - RELAXED =====
            v_mean = float(np.mean(v.astype(np.float32)))
            # Gi·∫£m t·ª´ 101.3892 -> 80 ƒë·ªÉ ch·∫•p nh·∫≠n l·ª≠a t·ªëi h∆°n
            if v_mean < 80:
                if debug:
                    print(f"‚ùå FAIL T2: Qu√° t·ªëi")
                    print(f"   ƒêo ƒë∆∞·ª£c: V_mean={v_mean:.1f}")
                    print(f"   Y√™u c·∫ßu: V_mean>=80")
                return False
            
            if debug:
                print(f"‚úÖ PASS T2: ƒê·ªß s√°ng")
                print(f"   ƒêo ƒë∆∞·ª£c: V_mean={v_mean:.1f}, y√™u c·∫ßu >=80")
            
            # ===== TI√äU CH√ç 3: Saturation - RELAXED =====
            s_mean = float(np.mean(s.astype(np.float32)))
            s_std = float(np.std(s.astype(np.float32)))
            
            # Detect lo·∫°i camera ƒë·ªÉ √°p d·ª•ng logic kh√°c nhau
            v_std = float(np.std(v.astype(np.float32)))
            is_thermal_camera = (s_mean < 15) and (v_std > 25)
            
            if debug:
                camera_type = "üî¥ THERMAL" if is_thermal_camera else "üì± RGB"
                print(f"üì∑ Camera: {camera_type} (S_mean={s_mean:.1f}, V_std={v_std:.1f})")
            
            # V·ªõi RGB camera: ki·ªÉm tra saturation ƒë·ªÉ lo·∫°i b·ªè √°nh s√°ng tr·∫Øng
            # Gi·∫£m t·ª´ 20 -> 15 ƒë·ªÉ ch·∫•p nh·∫≠n nhi·ªÅu h∆°n
            if not is_thermal_camera and s_mean < 15:
                if debug:
                    print(f"‚ùå FAIL T3: √Ånh s√°ng tr·∫Øng (saturation th·∫•p)")
                    print(f"   ƒêo ƒë∆∞·ª£c: S_mean={s_mean:.1f}")
                    print(f"   Y√™u c·∫ßu: S_mean>=15 (ho·∫∑c thermal camera)")
                return False
            
            if debug:
                print(f"‚úÖ PASS T3: Saturation OK")
                print(f"   ƒêo ƒë∆∞·ª£c: S_mean={s_mean:.1f}, y√™u c·∫ßu >=15")
            
            # ===== TI√äU CH√ç 4: RGB Ratio - RELAXED =====
            b, g, r = cv2.split(roi.astype(np.float32))
            r_mean = float(np.mean(r.astype(np.float32)))
            g_mean = float(np.mean(g.astype(np.float32)))
            b_mean = float(np.mean(b.astype(np.float32)))
            
            channel_max = max(r_mean, g_mean, b_mean)
            channel_min = min(r_mean, g_mean, b_mean)
            
            rgb_ratio = channel_min / channel_max if channel_max > 0 else 1.0
            
            # Ch·ªâ lo·∫°i b·ªè √°nh s√°ng tr·∫Øng r√µ r√†ng
            # Gi·∫£m t·ª´ 0.8923 -> 0.92 ƒë·ªÉ strict h∆°n v·ªõi white light
            if not is_thermal_camera and rgb_ratio > 0.92:
                if debug:
                    print(f"‚ùå FAIL T4: √Ånh s√°ng tr·∫Øng (R‚âàG‚âàB)")
                    print(f"   ƒêo ƒë∆∞·ª£c: R={r_mean:.1f}, G={g_mean:.1f}, B={b_mean:.1f}, ratio={rgb_ratio:.3f}")
                    print(f"   Y√™u c·∫ßu: RGB_ratio<=0.92")
                return False
            
            if debug:
                print(f"‚úÖ PASS T4: RGB ratio OK")
                print(f"   ƒêo ƒë∆∞·ª£c: R={r_mean:.1f}, G={g_mean:.1f}, B={b_mean:.1f}, ratio={rgb_ratio:.3f}, y√™u c·∫ßu <=0.92")
            
            # ===== TI√äU CH√ç 5: Value Variance - RELAXED =====
            # L·ª≠a n√™n c√≥ bi·∫øn ƒë·ªïi c∆∞·ªùng ƒë·ªô (kh√¥ng ph·∫≥ng)
            # M·ªü r·ªông range t·ª´ (24.39, 88.59) -> (15, 100) ƒë·ªÉ ch·∫•p nh·∫≠n nhi·ªÅu h∆°n
            if v_std < 15:
                if debug:
                    print(f"‚ùå FAIL T5: Qu√° ƒë·ªìng nh·∫•t (kh√¥ng c√≥ bi·∫øn ƒë·ªïi)")
                    print(f"   ƒêo ƒë∆∞·ª£c: V_std={v_std:.1f}")
                    print(f"   Y√™u c·∫ßu: V_std>=15")
                return False
            
            if v_std > 100 and not is_thermal_camera:
                if debug:
                    print(f"‚ö†Ô∏è  WARNING T5: Bi·∫øn ƒë·ªïi qu√° cao ({v_std:.1f} > 100), c√≥ th·ªÉ l√† nhi·ªÖu")
                # Kh√¥ng reject, ch·ªâ c·∫£nh b√°o
            
            if debug:
                print(f"‚úÖ PASS T5: Value variance OK")
                print(f"   ƒêo ƒë∆∞·ª£c: V_std={v_std:.1f}, y√™u c·∫ßu 15-100")
            
            # ===== TI√äU CH√ç 6: Ki·ªÉm tra chuy·ªÉn ƒë·ªông (n·∫øu ƒë∆∞·ª£c b·∫≠t) =====
            if settings.camera.rgb.check_motion:
                motion_threshold = settings.camera.rgb.motion_threshold
                motion_std_min = settings.camera.rgb.motion_std_min
                
                has_motion = self._check_motion_infrared(frame, bbox, motion_threshold, motion_std_min, debug)
                if not has_motion:
                    if debug:
                        print(f"‚ùå FAIL T6: Kh√¥ng c√≥ chuy·ªÉn ƒë·ªông ƒë·∫∑c tr∆∞ng c·ªßa l·ª≠a")
                    return False
                
                if debug:
                    print(f"‚úÖ PASS T6: C√≥ chuy·ªÉn ƒë·ªông")
            
            # ‚úÖ PASS T·∫§T C·∫¢ C√ÅC TI√äU CH√ç
            if debug:
                camera_label = "THERMAL" if is_thermal_camera else "RGB"
                print(f"üî• ‚úÖ FIRE VALIDATED ({camera_label}): hue={hue_ratio:.2f}, bright={v_mean:.0f}, sat={s_mean:.0f}, var={v_std:.0f}\n")
            
            return True
            
        except Exception as e:
            if debug:
                print(f"‚ö†Ô∏è  Color filter error: {e}")
            # Khi c√≥ l·ªói, ch·∫•p nh·∫≠n detection t·ª´ YOLO (thay v√¨ reject)
            return True

    def _handle_fire_detections(
        self,
        detections: list,
        scale_x: float,
        scale_y: float,
        now: float,
        frame: np.ndarray
    ):
        """X·ª≠ l√Ω c√°c ph√°t hi·ªán ch√°y v√† x√°c ƒë·ªãnh m·ª©c ƒë·ªô c·∫£nh b√°o"""
        DEBUG = True
    
        valid_detections = []
        for d in detections:
            result = self._is_valid_fire_color(frame, d['bbox'], debug=self._debug_fire_detection)
            if result:
                valid_detections.append(d)
        
        if not valid_detections:
            return

        # C·∫≠p nh·∫≠t c√°c h·ªôp l·ª≠a hi·ªán t·∫°i ƒë·ªÉ hi·ªÉn th·ªã
        for det in valid_detections:
            x1, y1, x2, y2 = det['bbox']
            x1_orig = int(x1 * scale_x)
            y1_orig = int(y1 * scale_y)
            x2_orig = int(x2 * scale_x)
            y2_orig = int(y2 * scale_y)
            self.current_fire_boxes.append((x1_orig, y1_orig, x2_orig, y2_orig))
        # Th√™m v√†o l·ªãch s·ª≠
        for det in valid_detections:
            det['timestamp'] = now
            self.recent_fire_detections.append(det)
        
        # Ki·ªÉm tra xem kh√≥a c·∫£nh b√°o ƒë·ªè ƒë√£ h·∫øt h·∫°n ch∆∞a
        if self.red_alert_mode_active and now > self.red_alert_mode_until:
            self.red_alert_mode_active = False
            print("INFO: Red alert lockdown expired")
            print("INFO: Ch·∫ø ƒë·ªô kh√≥a C·∫£nh b√°o ƒê·ªè ƒë√£ h·∫øt h·∫°n.")
        
        if not self.recent_fire_detections:
            return
        
        # --- LOGIC C·∫¢NH B√ÅO ƒê·ªé (KH·∫®N C·∫§P) ---
        
        # X√°c ƒë·ªãnh m·ª©c ƒë·ªô c·∫£nh b√°o
        is_red_alert = False
        
        if self.red_alert_mode_active and valid_detections:
            is_red_alert = True
        else:
            # Ki·ªÉm tra s·ª± ph√°t tri·ªÉn c·ªßa ƒë√°m ch√°y
            # N·∫øu c√≥ nhi·ªÅu ph√°t hi·ªán trong th·ªùi gian ng·∫Øn -> C·∫£nh b√°o ƒë·ªè
            recent_count = len(self.recent_fire_detections)
            
            # Ng∆∞·ª°ng s·ªë l∆∞·ª£ng ph√°t hi·ªán ƒë·ªÉ k√≠ch ho·∫°t c·∫£nh b√°o ƒë·ªè
            # Gi·∫£m ng∆∞·ª°ng n·∫øu ·ªü ch·∫ø ƒë·ªô IR (v√¨ ƒë√£ l·ªçc k·ªπ)
            count_threshold = settings.fire_logic.confirmation_count
            if self._is_infrared_mode:
                count_threshold = max(1, int(count_threshold * 0.7))
            
            if recent_count >= count_threshold:
                is_red_alert = True
                # K√≠ch ho·∫°t ch·∫ø ƒë·ªô kh√≥a c·∫£nh b√°o ƒë·ªè
                self.red_alert_mode_active = True
                self.red_alert_mode_until = now + settings.fire_logic.red_alert_lockdown_duration
                print(f"INFO: Red alert activated (count={recent_count})")
        
        if is_red_alert:
            if self.on_fire_alert:
                # G·ª≠i c·∫£nh b√°o ƒë·ªè
                # Chu·∫©n b·ªã metadata
                metadata = {
                    "confidence": max([d.get('conf', 0) for d in valid_detections]),
                    "box_count": len(valid_detections),
                    "is_infrared": self._is_infrared_mode
                }
                
                # T·∫°o frame ch√∫ th√≠ch
                alert_frame = frame.copy()
                self._draw_visualizations(alert_frame, self._last_person_detection_enabled)
                
                self.on_fire_alert(self.source_id, alert_frame, AlertType.FIRE_RED, metadata)
            return

        # --- LOGIC C·∫¢NH B√ÅO V√ÄNG (C·∫¢NH B√ÅO S·ªöM) ---
        
        # N·∫øu c√≥ ph√°t hi·ªán nh∆∞ng ch∆∞a ƒë·ªß ƒë·ªÉ k√≠ch ho·∫°t ƒë·ªè -> C·∫£nh b√°o v√†ng
        # Ki·ªÉm tra b·ªô l·ªçc v√†ng (l·ªèng h∆°n)
        is_yellow_alert = False
        
        # Ki·ªÉm tra xem kh√≥a c·∫£nh b√°o v√†ng ƒë√£ h·∫øt h·∫°n ch∆∞a
        if self.yellow_alert_mode_active and now > self.yellow_alert_mode_until:
            self.yellow_alert_mode_active = False
        
        # Ch·ªâ k√≠ch ho·∫°t v√†ng n·∫øu ch∆∞a active ho·∫∑c ƒë√£ h·∫øt h·∫°n
        if not self.yellow_alert_mode_active:
            # Ki·ªÉm tra xem c√≥ ph√°t hi·ªán n√†o th·ªèa m√£n b·ªô l·ªçc v√†ng kh√¥ng
            valid_yellow_detections = []
            for d in detections: # Check all detections, not just valid_detections (which passed red filter)
                 # N·∫øu ƒë√£ pass red filter th√¨ ch·∫Øc ch·∫Øn pass yellow
                if d in valid_detections:
                    valid_yellow_detections.append(d)
                    continue
                
                # N·∫øu fail red filter, check yellow filter
                if self._is_infrared_mode:
                    if self._is_valid_yellow_alert_infrared(frame, d['bbox'], debug=False):
                        valid_yellow_detections.append(d)
                else:
                    # Logic v√†ng cho RGB (t·∫°m th·ªùi d√πng l·∫°i logic ƒë·ªè nh∆∞ng ch·∫•p nh·∫≠n confidence th·∫•p h∆°n t·ª´ model)
                    # ·ªû ƒë√¢y ta gi·∫£ ƒë·ªãnh model ƒë√£ filter confidence th·∫•p r·ªìi
                    # N√™n n·∫øu fail red filter m√†u s·∫Øc th√¨ c√≥ th·ªÉ v·∫´n l√† kh√≥i ho·∫∑c l·ª≠a m·ªõi
                    pass 

            if valid_yellow_detections:
                is_yellow_alert = True
                self.yellow_alert_mode_active = True
                self.yellow_alert_mode_until = now + settings.fire_logic.yellow_alert_lockdown_duration
                print(f"INFO: Yellow alert activated")

        if is_yellow_alert:
            if self.on_fire_alert:
                metadata = {
                    "confidence": max([d.get('conf', 0) for d in detections]), # Use raw detections max conf
                    "box_count": len(detections),
                    "is_infrared": self._is_infrared_mode
                }
                
                alert_frame = frame.copy()
                self._draw_visualizations(alert_frame, self._last_person_detection_enabled)
                
                self.on_fire_alert(self.source_id, alert_frame, AlertType.FIRE_YELLOW, metadata)

    def get_infrared_status(self) -> bool:
        """Tr·∫£ v·ªÅ tr·∫°ng th√°i ch·∫ø ƒë·ªô h·ªìng ngo·∫°i hi·ªán t·∫°i"""
        return self._is_infrared_mode

    def _draw_visualizations(self, frame, person_detection_enabled):
        """V·∫Ω c√°c h·ªôp gi·ªõi h·∫°n v√† th√¥ng tin l√™n khung h√¨nh"""
        # V·∫Ω v√πng ch√°y
        for box in self.current_fire_boxes:
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 2)
            cv2.putText(frame, "FIRE", (box[0], box[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            
        # V·∫Ω ng∆∞·ªùi n·∫øu ƒë∆∞·ª£c b·∫≠t
        if person_detection_enabled and self.person_tracker:
            self.person_tracker.draw_tracks(frame)
            
        # V·∫Ω tr·∫°ng th√°i IR
        if self._is_infrared_mode:
            cv2.putText(frame, "IR MODE", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            if self.ir_enhancement_enabled:
                cv2.putText(frame, "ENHANCED", (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

        # V·∫Ω behavior analysis (n·∫øu c√≥)
        if self.behavior_analyzer and self.current_pose and self.current_pose.is_valid:
            try:
                # Scale keypoints t·ª´ process_size v·ªÅ frame size hi·ªán t·∫°i
                h, w = frame.shape[:2]
                proc_w, proc_h = settings.camera.process_size
                
                scale_x = w / proc_w
                scale_y = h / proc_h
                
                scaled_kps = self.current_pose.keypoints.copy()
                scaled_kps[:, 0] *= scale_x
                scaled_kps[:, 1] *= scale_y
                
                color = self.behavior_analyzer.visualizer.get_color(self.current_anomaly_score)
                self.behavior_analyzer.visualizer.draw_skeleton(frame, scaled_kps, self.current_pose.confidence, color)
                self.behavior_analyzer.visualizer.draw_info(frame, self.current_anomaly_score)
            except Exception as e:
                print(f"ERROR: Visualization error: {e}")

    def _update_frames(self, processed_frame, raw_frame):
        """C·∫≠p nh·∫≠t b·ªô ƒë·ªám khung h√¨nh m·ªôt c√°ch an to√†n"""
        with self._frame_lock:
            self._last_frame = processed_frame.copy()
            self._raw_frame = raw_frame.copy()
            
    def get_connection_status(self) -> bool:
        """Ki·ªÉm tra xem camera c√≥ ƒëang k·∫øt n·ªëi v√† ho·∫°t ƒë·ªông kh√¥ng"""
        if not self.cap or not self.cap.isOpened():
            return False
        
        # Ki·ªÉm tra th·ªùi gian khung h√¨nh cu·ªëi c√πng
        if time.time() - self._last_successful_frame > self._connection_timeout:
            return False
            
        return True
        
    def force_reconnect(self):
        """Bu·ªôc k·∫øt n·ªëi l·∫°i camera"""
        print(f"INFO: Forcing reconnection for camera {self.source_id}")
        self._reconnect()
        
    def reset_fire_state(self):
        """ƒê·∫∑t l·∫°i tr·∫°ng th√°i ph√°t hi·ªán ch√°y"""
        self.recent_fire_detections.clear()
        self.current_fire_boxes = []
        self.red_alert_mode_active = False
        self.yellow_alert_mode_active = False
        print(f"INFO: Fire state reset for camera {self.source_id}")

    def set_ir_enhancement(self, enabled: bool):
        """B·∫≠t/t·∫Øt t√≠nh nƒÉng tƒÉng c∆∞·ªùng ·∫£nh h·ªìng ngo·∫°i"""
        self.ir_enhancement_enabled = enabled
        print(f"INFO: IR enhancement for camera {self.source_id} set to {enabled}")

    def release(self):
        """Gi·∫£i ph√≥ng t√†i nguy√™n"""
        self.quit = True
        if self.cap:
            self.cap.release()
        print(f"INFO: Camera released: {self.source}")
